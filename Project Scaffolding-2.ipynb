{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25627e8d",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [ ] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4212b1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.9/site-packages (3.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.9/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install matplotlib\n",
    "# !pip install  fastparquet==0.7.1\n",
    "# !pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import math\n",
    "import requests\n",
    "import re\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b622a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any general notebook setup, like log formatting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need, for example:\n",
    "\n",
    "TAXI_URL = \"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "# add other constants to refer to any local data, e.g. uber & weather\n",
    "UBER_CSV = \"uber_rides_sample.csv\"\n",
    "weather_2009_CSV=\"2009_weather.csv\"\n",
    "weather_2010_CSV=\"2010_weather.csv\"\n",
    "weather_2011_CSV=\"2011_weather.csv\"\n",
    "weather_2012_CSV=\"2012_weather.csv\"\n",
    "weather_2013_CSV=\"2013_weather.csv\"\n",
    "weather_2014_CSV=\"2014_weather.csv\"\n",
    "\n",
    "\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf38168",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library.\n",
    "* [ ] Taxi data:\n",
    "    * [ ] Use the `re` module, and the packages `requests`, BeautifulSoup (`bs4`), and (optionally) `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* [ ] Weather & Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "* [ ] All data:\n",
    "    * [ ] Load the data using `pandas`\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * (Taxi & Uber data) Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] (Taxi data) Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* [ ] Weather data:\n",
    "    * [ ] Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "    * [ ] You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what youâ€™re doing so we can follow along. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(from_coord, to_coord):\n",
    "    #return the euclidean distance between start and end coordinate\n",
    "    from math import sin, cos, sqrt, atan2, radians\n",
    "    R = 6373.0 #approximate radius of earth in km\n",
    "    lon1=radians(from_coord[0])\n",
    "    lat1=radians(from_coord[1])\n",
    "    lon2=radians(to_coord[0])\n",
    "    lat2=radians(to_coord[1])\n",
    "    dlon=lon2-lon1\n",
    "    dlat=lat2-lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    b = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance=R*b\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lon_lat(dataframe):\n",
    "    zone_file=gpd.read_file(\"taxi_zones\")\n",
    "    zone_file['geometry']=zone_file['geometry'].to_crs(4326)\n",
    "    zone_file[\"lon\"]=zone_file['geometry'].centroid.x\n",
    "    zone_file[\"lat\"]=zone_file['geometry'].centroid.y\n",
    "    pick=zone_file[[\"LocationID\",\"lon\",\"lat\"]]\n",
    "    pick.columns=[\"PULocationID\",\"pickup_longitude\",\"pickup_latitude\"]\n",
    "    drop=zone_file[[\"LocationID\",\"lon\",\"lat\"]]\n",
    "    drop.columns=[\"DOLocationID\",\"dropoff_longitude\",\"dropoff_latitude\"]\n",
    "    #merge pick and drop to dataframe\n",
    "    #merge pick \n",
    "    dataframe=pd.merge(left=dataframe,right=pick)\n",
    "    #merge drop\n",
    "    dataframe=pd.merge(left=dataframe,right=drop)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_column(dataframe):\n",
    "    dataframe[\"distance\"]=dataframe.apply(lambda x: calculate_distance(x[\"pickup_longitude\",\"pickup_latitude\"],\n",
    "    x[\"dropoff_longitude\",\"dropoff_latitude\"]),axis=1)\n",
    "    return dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "508fb584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/jc_vc4mj42s708qkj0c26b6w0000gn/T/ipykernel_16211/1654112693.py:3: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  zone_file[\"lon\"]=zone_file['geometry'].centroid.x\n",
      "/var/folders/kh/jc_vc4mj42s708qkj0c26b6w0000gn/T/ipykernel_16211/1654112693.py:4: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  zone_file[\"lat\"]=zone_file['geometry'].centroid.y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-74.174000</td>\n",
       "      <td>40.691831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-73.831299</td>\n",
       "      <td>40.616745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-73.847422</td>\n",
       "      <td>40.864474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-73.976968</td>\n",
       "      <td>40.723752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-74.188484</td>\n",
       "      <td>40.552659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>259</td>\n",
       "      <td>-73.852215</td>\n",
       "      <td>40.897932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>260</td>\n",
       "      <td>-73.906306</td>\n",
       "      <td>40.744235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>261</td>\n",
       "      <td>-74.013023</td>\n",
       "      <td>40.709139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>-73.946510</td>\n",
       "      <td>40.775932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>263</td>\n",
       "      <td>-73.951010</td>\n",
       "      <td>40.778766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>263 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LocationID        lon        lat\n",
       "0             1 -74.174000  40.691831\n",
       "1             2 -73.831299  40.616745\n",
       "2             3 -73.847422  40.864474\n",
       "3             4 -73.976968  40.723752\n",
       "4             5 -74.188484  40.552659\n",
       "..          ...        ...        ...\n",
       "258         259 -73.852215  40.897932\n",
       "259         260 -73.906306  40.744235\n",
       "260         261 -74.013023  40.709139\n",
       "261         262 -73.946510  40.775932\n",
       "262         263 -73.951010  40.778766\n",
       "\n",
       "[263 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zone_file=gpd.read_file(\"taxi_zones\")\n",
    "zone_file['geometry']=zone_file['geometry'].to_crs(4326)\n",
    "zone_file[\"lon\"]=zone_file['geometry'].centroid.x\n",
    "zone_file[\"lat\"]=zone_file['geometry'].centroid.y\n",
    "zone_file[[\"LocationID\",\"lon\",\"lat\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3b5fc",
   "metadata": {},
   "source": [
    "From above table, we know that loction ID is valid between 1 and 263. Thus, we can use it to clean our taxi dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5177e9d2",
   "metadata": {},
   "source": [
    "Before we processing taxi data, let's have a explore one of the taxi dataset. So that we know how to clean the dataset. First, we write a function called find_taxi_Parquet_urls, which will return urls for Parquet dataset from January 2009 through June 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxi_Parquet_urls():\n",
    "    url=TAXI_URL #url for taxi data page is set above\n",
    "    url_list=list()\n",
    "    response=requests.get(url)\n",
    "    if response.status_code!=200:\n",
    "        print(\"Failure: fail to request data\")\n",
    "        return result\n",
    "    try:\n",
    "        result_page=BeautifulSoup(response.content,'lxml')\n",
    "        result_tags=result_page.find_all(\"a\",{\"title\":\"Yellow Taxi Trip Records\"})\n",
    "        for element in result_tags:\n",
    "            newurl=element.get('href')\n",
    "            url_list.append(newurl)\n",
    "        result=url_list[85:] #only include dataset link from January 2009 through June 2015 \n",
    "    except:\n",
    "        print(\"Failure: scraping fail\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1629a68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-06.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-07.parquet',\n",
       " 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2015-08.parquet']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=find_taxi_Parquet_urls()\n",
    "result[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c363af2",
   "metadata": {},
   "source": [
    "Next, we explore one of the taxi dataset to deside how to process the data. Here we choose 2015 June. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19eba95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/fastparquet/dataframe.py:5: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import (\n"
     ]
    }
   ],
   "source": [
    "#choose 2015 June. \n",
    "data_url=result[0]\n",
    "df=pd.read_parquet(data_url,engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099f2c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-01 00:04:04</td>\n",
       "      <td>2015-06-01 00:13:02</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-01 00:42:13</td>\n",
       "      <td>2015-06-01 00:52:37</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>87</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-01 00:24:29</td>\n",
       "      <td>2015-06-01 00:50:18</td>\n",
       "      <td>4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>164</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-01 00:11:03</td>\n",
       "      <td>2015-06-01 00:19:47</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>163</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-01 00:20:29</td>\n",
       "      <td>2015-06-01 00:52:44</td>\n",
       "      <td>1</td>\n",
       "      <td>19.6</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.54</td>\n",
       "      <td>0.3</td>\n",
       "      <td>58.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2015-06-01 00:04:04   2015-06-01 00:13:02                1   \n",
       "1         1  2015-06-01 00:42:13   2015-06-01 00:52:37                1   \n",
       "2         1  2015-06-01 00:24:29   2015-06-01 00:50:18                4   \n",
       "3         1  2015-06-01 00:11:03   2015-06-01 00:19:47                1   \n",
       "4         1  2015-06-01 00:20:29   2015-06-01 00:52:44                1   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            1.1           1                  N            79           148   \n",
       "1            3.4           1                  N            87            68   \n",
       "2            5.4           1                  N           164             7   \n",
       "3            2.8           1                  N           163            24   \n",
       "4           19.6           2                  N           132           151   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             3          7.5    0.5      0.5        0.00          0.00   \n",
       "1             1         12.0    0.5      0.5        1.50          0.00   \n",
       "2             1         21.0    0.5      0.5        2.00          0.00   \n",
       "3             1         10.0    0.5      0.5        2.25          0.00   \n",
       "4             2         52.0    0.0      0.5        0.00          5.54   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    0.3          8.80                   NaN          NaN  \n",
       "1                    0.3         14.80                   NaN          NaN  \n",
       "2                    0.3         24.30                   NaN          NaN  \n",
       "3                    0.3         13.55                   NaN          NaN  \n",
       "4                    0.3         58.34                   NaN          NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a4c05c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/jc_vc4mj42s708qkj0c26b6w0000gn/T/ipykernel_16211/325126572.py:4: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  zone_file[\"lon\"]=zone_file['geometry'].centroid.x\n",
      "/var/folders/kh/jc_vc4mj42s708qkj0c26b6w0000gn/T/ipykernel_16211/325126572.py:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  zone_file[\"lat\"]=zone_file['geometry'].centroid.y\n"
     ]
    }
   ],
   "source": [
    "a=add_distance_column(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c8a6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"distance\"]=a.apply(lambda x:calculate_distance([x[\"Pick_lon\"],x[\"Pick_lat\"]], [x[\"Drop_lon\"],x[\"Drop_lat\"]]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bd7858c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>...</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>Pick_lon</th>\n",
       "      <th>Pick_lat</th>\n",
       "      <th>Drop_lon</th>\n",
       "      <th>Drop_lat</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-01 00:04:04</td>\n",
       "      <td>2015-06-01 00:13:02</td>\n",
       "      <td>1</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.985937</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>1.052271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-01 00:52:54</td>\n",
       "      <td>2015-06-01 00:56:33</td>\n",
       "      <td>2</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.985937</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>1.052271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-01 00:00:42</td>\n",
       "      <td>2015-06-01 00:05:20</td>\n",
       "      <td>3</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.985937</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>1.052271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-01 00:28:04</td>\n",
       "      <td>2015-06-01 00:30:41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.985937</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>1.052271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-01 00:36:29</td>\n",
       "      <td>2015-06-01 00:37:23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.985937</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-73.990896</td>\n",
       "      <td>40.718938</td>\n",
       "      <td>1.052271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098116</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-16 08:27:15</td>\n",
       "      <td>2015-06-16 08:35:49</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.882658</td>\n",
       "      <td>40.791133</td>\n",
       "      <td>-73.882658</td>\n",
       "      <td>40.791133</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098117</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-16 08:40:36</td>\n",
       "      <td>2015-06-16 08:56:38</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.882658</td>\n",
       "      <td>40.791133</td>\n",
       "      <td>-73.882658</td>\n",
       "      <td>40.791133</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098118</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-16 08:59:13</td>\n",
       "      <td>2015-06-16 09:14:07</td>\n",
       "      <td>1</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.882658</td>\n",
       "      <td>40.791133</td>\n",
       "      <td>-73.882658</td>\n",
       "      <td>40.791133</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098119</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-16 09:15:56</td>\n",
       "      <td>2015-06-16 09:42:44</td>\n",
       "      <td>2</td>\n",
       "      <td>6.10</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>29.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.882658</td>\n",
       "      <td>40.791133</td>\n",
       "      <td>-73.882658</td>\n",
       "      <td>40.791133</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12098120</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-06-16 10:19:17</td>\n",
       "      <td>2015-06-16 10:24:38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>199</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-73.882658</td>\n",
       "      <td>40.791133</td>\n",
       "      <td>-73.882658</td>\n",
       "      <td>40.791133</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12098121 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "0                1  2015-06-01 00:04:04   2015-06-01 00:13:02   \n",
       "1                1  2015-06-01 00:52:54   2015-06-01 00:56:33   \n",
       "2                2  2015-06-01 00:00:42   2015-06-01 00:05:20   \n",
       "3                1  2015-06-01 00:28:04   2015-06-01 00:30:41   \n",
       "4                2  2015-06-01 00:36:29   2015-06-01 00:37:23   \n",
       "...            ...                  ...                   ...   \n",
       "12098116         1  2015-06-16 08:27:15   2015-06-16 08:35:49   \n",
       "12098117         1  2015-06-16 08:40:36   2015-06-16 08:56:38   \n",
       "12098118         1  2015-06-16 08:59:13   2015-06-16 09:14:07   \n",
       "12098119         1  2015-06-16 09:15:56   2015-06-16 09:42:44   \n",
       "12098120         1  2015-06-16 10:19:17   2015-06-16 10:24:38   \n",
       "\n",
       "          passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "0                       1           1.10           1                  N   \n",
       "1                       2           0.80           1                  N   \n",
       "2                       3           1.14           1                  N   \n",
       "3                       1           0.50           1                  N   \n",
       "4                       1           0.19           1                  N   \n",
       "...                   ...            ...         ...                ...   \n",
       "12098116                1           1.00           1                  N   \n",
       "12098117                1           2.80           1                  N   \n",
       "12098118                1           1.70           1                  N   \n",
       "12098119                2           6.10           1                  N   \n",
       "12098120                1           0.50           1                  N   \n",
       "\n",
       "          PULocationID  DOLocationID  payment_type  ...  tolls_amount  \\\n",
       "0                   79           148             3  ...           0.0   \n",
       "1                   79           148             1  ...           0.0   \n",
       "2                   79           148             2  ...           0.0   \n",
       "3                   79           148             1  ...           0.0   \n",
       "4                   79           148             1  ...           0.0   \n",
       "...                ...           ...           ...  ...           ...   \n",
       "12098116           199           199             1  ...           0.0   \n",
       "12098117           199           199             1  ...           0.0   \n",
       "12098118           199           199             2  ...           0.0   \n",
       "12098119           199           199             1  ...           0.0   \n",
       "12098120           199           199             1  ...           0.0   \n",
       "\n",
       "          improvement_surcharge  total_amount  congestion_surcharge  \\\n",
       "0                           0.3          8.80                   NaN   \n",
       "1                           0.3          7.56                   NaN   \n",
       "2                           0.3          6.80                   NaN   \n",
       "3                           0.3          6.35                   NaN   \n",
       "4                           0.3          5.38                   NaN   \n",
       "...                         ...           ...                   ...   \n",
       "12098116                    0.3         10.14                   NaN   \n",
       "12098117                    0.3         16.56                   NaN   \n",
       "12098118                    0.3         11.80                   NaN   \n",
       "12098119                    0.3         29.76                   NaN   \n",
       "12098120                    0.3          6.96                   NaN   \n",
       "\n",
       "          airport_fee   Pick_lon   Pick_lat   Drop_lon   Drop_lat  distance  \n",
       "0                 NaN -73.985937  40.727620 -73.990896  40.718938  1.052271  \n",
       "1                 NaN -73.985937  40.727620 -73.990896  40.718938  1.052271  \n",
       "2                 NaN -73.985937  40.727620 -73.990896  40.718938  1.052271  \n",
       "3                 NaN -73.985937  40.727620 -73.990896  40.718938  1.052271  \n",
       "4                 NaN -73.985937  40.727620 -73.990896  40.718938  1.052271  \n",
       "...               ...        ...        ...        ...        ...       ...  \n",
       "12098116          NaN -73.882658  40.791133 -73.882658  40.791133  0.000000  \n",
       "12098117          NaN -73.882658  40.791133 -73.882658  40.791133  0.000000  \n",
       "12098118          NaN -73.882658  40.791133 -73.882658  40.791133  0.000000  \n",
       "12098119          NaN -73.882658  40.791133 -73.882658  40.791133  0.000000  \n",
       "12098120          NaN -73.882658  40.791133 -73.882658  40.791133  0.000000  \n",
       "\n",
       "[12098121 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "626f6bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 79,  87, 164, 163, 132, 237, 236, 229, 233, 234, 142, 243, 189,\n",
       "       148, 137, 249, 190,  62, 138, 230, 255,  37,  48, 170,  50,  74,\n",
       "       114, 140, 141, 161, 186, 100, 144, 238, 211, 246, 239, 116, 162,\n",
       "       261,  75,  90, 143, 152, 244, 226,   7,  41,  68, 181, 107,  43,\n",
       "       113, 231, 125, 158,  42, 151, 166,  24,  88,  45, 263,   4, 146,\n",
       "        13, 112, 256, 179,  25, 168,  97,  82, 145, 247,  40,  17,  49,\n",
       "       223, 127, 262, 219,  65,  33, 232,  92,  61, 260,  80, 129,  10,\n",
       "        70, 197, 224, 130,  95,  36, 134, 106,  52, 225,  63, 217, 188,\n",
       "        66, 209, 133,  56, 194, 215,  83,  28, 228, 257,  93, 157,  89,\n",
       "        12,  85, 193,  54,  26,  14, 195, 124,  76, 202, 216, 119, 123,\n",
       "       191,  71,  34, 242, 165, 196, 136, 173,   8,  15, 135, 227, 198,\n",
       "        39, 207, 160, 102, 235, 241, 131, 121,  53, 240, 171, 253, 192,\n",
       "       108,  96,  98,  73,   2, 177, 178,  69, 159,  94,  35, 150,  91,\n",
       "       180, 185, 208, 220, 175, 258, 126, 218,  55, 147, 200,  22,  23,\n",
       "        72,  29, 128, 221,  51, 213,  47,  77,  67, 259, 174,  19, 120,\n",
       "       248,  31,  99, 167, 250, 203, 111, 205, 155, 206,  64, 149,  38,\n",
       "       117,  18, 169, 182,  78, 212, 222,   6,  21,  60, 252,  16,   1,\n",
       "        20, 109, 184, 153,  32, 254,  11, 201,  58, 101, 214, 210, 139,\n",
       "         9, 154,  27, 156,   3, 183,  81,  59,  46, 118, 199, 122, 251,\n",
       "        86, 115, 187,  30, 245, 204,  84,  44, 172, 176,   5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"PULocationID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "efaf53e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int64\n",
       "tpep_pickup_datetime     datetime64[ns]\n",
       "tpep_dropoff_datetime    datetime64[ns]\n",
       "passenger_count                   int64\n",
       "trip_distance                   float64\n",
       "RatecodeID                        int64\n",
       "store_and_fwd_flag               object\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "payment_type                      int64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "congestion_surcharge            float64\n",
       "airport_fee                     float64\n",
       "Pick_lon                        float64\n",
       "Pick_lat                        float64\n",
       "Drop_lon                        float64\n",
       "Drop_lat                        float64\n",
       "distance                        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month_taxi_data(url):\n",
    "    #get month Taxi data\n",
    "    df=pd.read_parquet(url,engine='fastparquet')\n",
    "    #clean data\n",
    "    #select column\n",
    "    df=df[[\"tpep_pickup_datetime\",\"Trip_distance\",\"PULocationID\",\"DOLocationID\",\"Tip_amount\"]]\n",
    "    #remove any row with nan value\n",
    "    df.dropna()\n",
    "    #remove invalid locationIDï¼šlocation ID should between 1 and 263, and should be numeric\n",
    "    df[df[['PULocationID']].apply(lambda x: x[0].isdigit(), axis=1)]\n",
    "    df[df[['DOLocationID']].apply(lambda x: x[0].isdigit(), axis=1)]\n",
    "    df=df.loc[df[\"PULocationID\"]>=1 and df[\"PULocationID\"]<=263 and df[\"DOLocationID\"]>=1 and df[\"DOLocationID\"]<=263]\n",
    "    #add longitude and latitude based on location ID\n",
    "    df=get_lon_lat(df)\n",
    "    #appropriate column type\n",
    "\n",
    "    #remove outside the latitude/longitude coordinate box\n",
    "    df=df.loc[df[\"pickup_longitude\"]<=-73.717047 and df[\"pickup_longitude\"]>=-74.242330 \n",
    "    and df[\"pickup_latitude\"]<=40.908524 and df[\"pickup_latitude\"]>=40.560445\n",
    "    and df[\"dropoff_longitude\"]<=-73.717047 and df[\"dropoff_longitude\"]>=-74.242330 \n",
    "    and df[\"dropoff_latitude\"]<=40.908524  and df[\"dropoff_latitude\"]>=40.560445]\n",
    "\n",
    "    #normalize and usng appropriate coumn type\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    all_csv_urls = find_taxi_Parquet_urls()\n",
    "    for csv_url in all_csv_urls:\n",
    "        # maybe: first try to see if you've downloaded this exact\n",
    "        # file already and saved it before trying again\n",
    "        dataframe = get_and_clean_month_taxi_data(csv_url)\n",
    "        #add distance column \n",
    "        dataframe=add_distance_column(dataframe)\n",
    "        # maybe: if the file hasn't been saved, save it so you can\n",
    "        # avoid re-downloading it if you re-run the function\n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.contact(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4271e87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>2015-05-07 19:52:06.0000003</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>2009-07-17 20:04:56.0000002</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>2009-08-24 21:45:00.00000061</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>2009-06-26 08:22:21.0000001</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>2014-08-28 17:47:00.000000188</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                            key  fare_amount  \\\n",
       "0    24238194    2015-05-07 19:52:06.0000003          7.5   \n",
       "1    27835199    2009-07-17 20:04:56.0000002          7.7   \n",
       "2    44984355   2009-08-24 21:45:00.00000061         12.9   \n",
       "3    25894730    2009-06-26 08:22:21.0000001          5.3   \n",
       "4    17610152  2014-08-28 17:47:00.000000188         16.0   \n",
       "\n",
       "           pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0  2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
       "1  2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
       "2  2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
       "3  2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
       "4  2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
       "\n",
       "   dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0         -73.999512         40.723217                1  \n",
       "1         -73.994710         40.750325                1  \n",
       "2         -73.962565         40.772647                1  \n",
       "3         -73.965316         40.803349                3  \n",
       "4         -73.973082         40.761247                5  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber=pd.read_csv(\"uber_rides_sample.csv\")\n",
    "uber.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    df=pd.read_csv(csv_file)\n",
    "    #clean data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_DATA)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # only select columns will be used\n",
    "    selected = df[['DATE', 'HourlyWindSpeed', 'HourlyPrecipitation']]\n",
    "    # convert data type to number\n",
    "    selected['HourlyPrecipitation'] = pd.to_numeric(selected['HourlyPrecipitation'].replace(['T'], ''), errors='coerce')\n",
    "    selected['HourlyWindSpeed'] = pd.to_numeric(selected['HourlyWindSpeed'].replace(['T'], ''), errors='coerce')\n",
    "    selected['DATE'] = pd.to_datetime(selected['DATE'])\n",
    "    # filter na data\n",
    "    selected = selected.dropna()\n",
    "    return selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # only select columns will be used\n",
    "    selected = df[['HourlyWindSpeed', 'HourlyPrecipitation', 'DATE']]\n",
    "    # convert data type to number\n",
    "    selected['HourlyPrecipitation'] = pd.to_numeric(selected['HourlyPrecipitation'].replace(['T'], ''), errors='coerce')\n",
    "    selected['HourlyWindSpeed'] = pd.to_numeric(selected['HourlyWindSpeed'].replace(['T'], ''), errors='coerce')\n",
    "    # filter na data\n",
    "    selected = selected.dropna()\n",
    "    # convert data time to date string\n",
    "    selected['DATE'] = pd.to_datetime(selected['DATE']).dt.strftime('%Y-%m-%d')\n",
    "    # get average wind speed and toal percipitation of each day\n",
    "    daily_df = selected.groupby(['DATE']).agg({'HourlyWindSpeed': ['mean'], 'HourlyPrecipitation': ['sum']})\n",
    "    # rename df\n",
    "    daily_df.rename(columns = {'HourlyWindSpeed':'DailyWindSpeed', 'HourlyPrecipitation':'DailyPrecipitation'}, inplace = True)\n",
    "    return daily_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    # read all weather-like files from given path\n",
    "    import glob\n",
    "    weather_csv_files = list(glob.glob('./*weather*.csv'))\n",
    "    weather_csv_files.sort()\n",
    "\n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900f7aa",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "_This is where you can actually execute all the required functions._\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_data = get_and_clean_taxi_data()\n",
    "uber_data = get_uber_data()\n",
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "_Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE hourly_weather(\n",
    "   DATE timestamp PRIMARY KEY,\n",
    "   HourlyWindSpeed FLOAT,\n",
    "   HourlyPrecipitation FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE daily_weather(\n",
    "   DATE timestamp PRIMARY KEY,\n",
    "   DailyWindSpeed FLOAT,\n",
    "   DailyPrecipitation FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE taxis_trips(\n",
    "   pickup_datetime timestamp,\n",
    "   tip_amount FLOAT,\n",
    "   pickup_longitude DOUBLE,\n",
    "   pickup_latitude DOUBLE,\n",
    "   dropoff_longitude DOUBLE,\n",
    "   dropoff_latitude DOUBLE,\n",
    "   distance DOUBLE\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE uber_trips(\n",
    "   pickup_datetime timestamp,\n",
    "   pickup_longitude DOUBLE,\n",
    "   pickup_latitude DOUBLE,\n",
    "   dropoff_longitude DOUBLE,\n",
    "   dropoff_latitude DOUBLE,\n",
    "   distance DOUBLE\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to sql and store data to db\n",
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    for table_name, df in table_to_df_dict.items():\n",
    "        df.to_sql(name=table_name, con=engine.connect(), index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_data,\n",
    "    \"daily_weather\": daily_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4753fcd",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* [ ] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write sql to file at specified direction\n",
    "def write_query_to_file(query, outfile):\n",
    "    with open(QUERY_DIRECTORY + '/' + str(outfile), \"w\") as f:\n",
    "        f.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each query_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e380e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1 = \"\"\"\n",
    "select count(1) as heat, strftime('%H', pickup_datetime) as hour_of_day\n",
    "from taxi_trips\n",
    "where strftime('%s', pickup_datetime) BETWEEN strftime('%s', '2009-01-01') AND strftime('%s', '2015-06-30')\n",
    "group by strftime('%H', pickup_datetime)\n",
    "order by heat desc\n",
    "\"\"\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "select count(1) as heat, strftime('%w', pickup_datetime) as day_of_week\n",
    "from taxi_trips\n",
    "where strftime('%s', pickup_datetime) BETWEEN strftime('%s', '2009-01-01') AND strftime('%s', '2015-06-30')\n",
    "group by strftime('%w', pickup_datetime)\n",
    "order by heat desc\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "select * from (\n",
    "    SELECT distance,\n",
    "        ROW_NUMBER() OVER (ORDER BY distance DESC) AS rank\n",
    "    FROM taxi_trips\n",
    "    where strftime('%Y-%m', pickup_datetime) == \"2013-07\"\n",
    ")\n",
    "where rank = (select ROUND((count(1) - 1) * (1 - 0.95)) from taxi_trips where strftime('%Y-%M', pickup_datetime) == \"2013-07\")\n",
    "\"\"\"\n",
    "\n",
    "QUERY_4= \"\"\"\n",
    "select strftime('%Y-%m-%d', pickup_datetime), count(1) as heat, avg(distance) as avg_dist\n",
    "from taxi_trips\n",
    "where strftime('%Y', pickup_datetime) = '2009'\n",
    "group by strftime('%Y-%m-%d', pickup_datetime)\n",
    "order by heat desc\n",
    "limit 10\n",
    "\"\"\"\n",
    "\n",
    "QUERY_5= \"\"\"\n",
    "with weather as (\n",
    "    select date, DailyWindSpeed from daily_weather \n",
    "    where strftime('%Y', date) = '2014'\n",
    "    order by DailyWindSpeed desc\n",
    "    limit 10\n",
    "),\n",
    "all_trip as (\n",
    "    select pickup_datetime from taxi_trips\n",
    "    where strftime('%Y', pickup_datetime) = '2014'\n",
    "    union all\n",
    "    select pickup_datetime from uber_trips\n",
    "    where strftime('%Y', pickup_datetime) = '2014'\n",
    ")\n",
    "select date, max(DailyWindSpeed), count(1) as heat\n",
    "from weather\n",
    "left join all_trip\n",
    "on weather.date = strftime('%Y-%m-%d', all_trip.pickup_datetime)\n",
    "group by weather.date\n",
    "order by date asc\n",
    "\"\"\"\n",
    "\n",
    "QUERY_6= \"\"\"\n",
    "with all_trip as (\n",
    "    select pickup_datetime from taxi_trips\n",
    "    where strftime('%s', pickup_datetime) BETWEEN strftime('%s', '2012-10-22') AND strftime('%s', '2012-10-30')\n",
    "    union all\n",
    "    select pickup_datetime from uber_trips\n",
    "    where strftime('%s', pickup_datetime) BETWEEN strftime('%s', '2012-10-22') AND strftime('%s', '2012-10-30')\n",
    "),\n",
    "trip_aggr as (\n",
    "    select strftime('%Y-%m-%d:%H', pickup_datetime) as day_hour, count(1) as heat\n",
    "    from all_trip\n",
    "    group by strftime('%Y-%m-%d:%H', pickup_datetime)\n",
    ")\n",
    "select day_hour, heat, coalesce(HourlyWindSpeed, 0), coalesce(HourlyPrecipitation,0)\n",
    "from trip_aggr\n",
    "left join hourly_weather\n",
    "on trip_aggr.day_hour = strftime('%Y-%m-%d:%H', hourly_weather.date)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get retrieval result of given sql\n",
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e0f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_2).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_3).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce51c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_4).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d84952",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_5).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9852c",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_6).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, \"taxi_hourly_trip.sql\")\n",
    "write_query_to_file(QUERY_2, \"uber_daily_trip.sql\")\n",
    "write_query_to_file(QUERY_3, \"upper_trip_distance.sql\")\n",
    "write_query_to_file(QUERY_4, \"2009_peak_ten.sql\")\n",
    "write_query_to_file(QUERY_5, \"trip_count_windiest.sql\")\n",
    "write_query_to_file(QUERY_6, \"Hurricane_Sandy.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization N\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._\n",
    "\n",
    "_Repeat for each visualization._\n",
    "\n",
    "_The example below makes use of the `matplotlib` library. There are other libraries, including `pandas` built-in plotting library, kepler for geospatial data representation, `seaborn`, and others._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_n(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_n():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplemented()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_n()\n",
    "plot_visual_n(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
